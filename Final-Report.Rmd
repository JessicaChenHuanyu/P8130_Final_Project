---
title: "**P8130 Final Report (Project 1)**"
author: 
- "Huanyu Chen (hc3451)   Xiaoting Tang (xt2288)"
- "Yifei Liu (yl5508)     Longyu Zhang (lz2951)"
output:
  pdf_document:
    latex_engine: pdflatex
fontsize: 11pt
linestretch: 1.75
---

```{r, include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
library(MASS)
library(glmnet)
library(leaps)
library(corrplot)

set.seed(1)
```

# Abstract
This study used regression modeling techniques to predict academic performance in math, reading, and writing based on multiple variables, including personal characteristics and socio-environmental factors. Using stepwise regression, criterion-based procedures, and LASSO analyses, we found significant relationships between test scores and several covariants, including gender, race, parent education, lunch type, test preparation, and weekly study time. We further found that including another test score as a predictor (e.g., consider reading scores when predicting math scores) significantly enhanced model performance. This comprehensive analysis reveals the complex relationships between predictors and student performance, providing suggestions to educators and thus achieving overall student progress.

# Introduction

The objective of this study is to use regression models to predict
academic performance in math, reading, and writing based on various
variables, including personal characteristics such as gender, ethnicity, test preparation, and weekly study hours, as well as socio-environmental factors like lunch type, transportation and parent education. Furthermore, the study aims to identify potential correlations and regression models between scores among different subjects. The combination of these analyses is
intended to provide educators and policymakers with practical insights for tailoring interventions.

# Methods

This dataset provides information on public school students, including
three test scores and various personal and socioeconomic factors. To
facilitate analysis, categorical data have been converted to numerical
representations based on their ordinal order or type.

When pre-processing the data, we created a summary of the factorial data, including the number of missing data, the
number of categories under each variable, and the top counts. For the
numeric data (three test scores), we constructed a comprehensive
descriptive table to provide a snapshot of central
tendencies and variability. Then, we have excluded
the missing cells because predictor variables that we have are factorial data types. The distribution of the three response
variables is also tested in both histogram and boxplot.

Then we fitted the "full model" using the score of three subjects as the response variables, which consists of all 11
categorical variables as predictors. The model diagnostics are conducted by generating four plots for each model: Residuals vs Fitted, Q-Q Residuals, Scale-Location, and Residuals vs Leverage. Next, we use BIC-based procedures to select the appropriate subsets of predictors for three subjects.

Based on the full models, we did some tests and calculations: First, we conducted the boxcox method to determine if there was any transformation needed. Second, we calculated Cook's distance to check the existence of outliers and influence points. Finally, in order to test the multicollinearity among predictors, we calculated VIF as the criterion of multicollinearity.

After all the steps above, we conducted model selection using stepwise selection method, criterion-based procedures and LASSO method. We tested predictors, coefficients, and p-values for stepwise method; as well as predictors and estimated coefficients for BIC-based method. In the selection procedure using LASSO method, for each subject we used
cross-validation to decide the optimal value of method parameter $\lambda$, and then fitted LASSO model with this optimal value.

Finally, we tried to figure out if it is possible to leverage one score as the auxiliary information to learn the model for another score (still its model against variables 1-11) better. we plotted the correlation among three score variables. Then we refitted the linear models for the scores of three subjects using eleven categorical variables and one other score variable of a different subject as predictors. The VIFs are calculated for all six models generated in this step to reveal the potential
multicollinearity.s

# Results

**Table 1** gives the summary of the factorial data. **Table 2** provides the mean, deviation, and quantile information about the continuous data (score variables of three subjects). A total of 786 missing values were identified. After removing the missing values from the original dataset, 354 observations remained out of the initial 948. Since categorical variables hold specific meanings on their values, we opted not to impute missing values using the mean.

The distributions of three response score variables are demonstrated in **Figure 1** (histogram) and **Figure 2** (boxplot). Both the histogram and boxplot distributions showed a normal distribution. Overall, the score distributions for the three subjects are quite similar, with an average around 70 points. As indicated by the boxplot, outliers are predominantly situated within the lower score ranges.

**Figure 3, 4, 5** display the diagnostic plots generated by the model. The diagnosis of full models indicated that the model adheres to the basic assumptions of linear regression, including homoscedasticity, normality, independent residuals with constant variance, and that there was no need for transformations.

**Figure 6** demonstrates the results of boxcox method: the log-likelihood over boxcox method parameter $\lambda$. The biggest likelihood is at around $\lambda=1$, showing that there’s no need for transformation. **Figure 7** demonstrates the Cook's distance, which is an indicator to identify influential outliers within a data set. In R code, rule of thumb suggests that Cook’s distance exceeding 0.5 indicates potential influence. Based on this criterion, it appears that there's no necessity to eliminate any outliers in this case.

**Table 3, 4, 5** display the regression models for math, reading, and writing scores using multiple stepwise regression. To be specific, `gender`, `ethnic group`, `lunch type`, `test preparation`, `parent marital status`, and `weekly study hours` were found to be significant variables for math scores, with an adjusted R-squared of 0.27. Similarly, the multiple stepwise regression models for reading and writing scores also revealed statistically significant relationships between test scores and predictors, including `gender`, `ethnicity`, `parental education`, `lunch type`, `test preparation`, `parental marital status`, and `weekly study hours`. These predictors explain the model with an adjusted R-squared of 0.25 for reading and 0.33 for writing.

**Table 6, 7, 8** display the result of multicollinearity test: VIFs for three full models. In this model, all VIF values are quite low, ranging between 1 and 1.5, indicating no collinearity issues.

**Figure 8** displays the relationship between BIC values and the number of selected model variables. Criterion-based procedures suggest that employing regression models for three test scores with 4 or 5 predictors will yield optimal results with a minimum Bayesian information criterion. The chosen variables are displayed in **Table 9, 10, 11**. Unlike stepwise regression models, criterion-based procedures streamline the selection by excluding the variables `parent marital status` from the math scores model and `parental education`, `parental marital status` from both the reading and writing scores models.

For LASSO model, we demonstrate the process of selecting the optimal lambda value. In **Figures 9-11**, we identify the lambda value corresponding to the minimum mean cross-validation error as providing the best fit for the model. **Figures 12-14** illustrate the relationship between lambda values and the degree of variable shrinkage. **Table 12, 13, 14** show the selected variables by LASSO. Comparing to stepwise regression models, LASSO expanded the model of math scores by including `parental education`, `time spent in sports`, and `the number of siblings`, and it expands the models of writing scores by including `the number of siblings`. The model of reading scores holds the same as which generated from stepwise regression model.

**Figure 15** shows the correlation among score variables, suggesting the feasibility of using one of the score variables as the auxiliary information to learn another one. **Table 15-20** are the results of regression using one subject score as an additional predictor for the prediction of another subject score. **Table 21-26** shows the VIFs of these six models, indicating there is still no multicollinearity among predictors. Generally speaking, the inclusion of an additional test score as a predictor resulted in a significant increase in the adjusted R square to greater than 0.8 without introducing collinearity problems or altering the effects of the existing predictors. This emphasizes the interdependence of test scores and their potential as predictive variables for each other, thereby enhancing the models' predictive capacity.

# Conclusions

Overall, we tried several regression models that worked successfully in pointing out the key factors affecting math, reading, and writing scores and in quantifying the specific effects of different classifications in these factors. We would like to highlight that including another test score as a predictor can significantly enhanced performance of regression model among all three subjects. 

Although the categorical data provided feasibility results, we found that some points were still not fully explained by the regression model. This limitation suggests the need for broader and more detailed data collection. With continuous refinement of the data, we may be able to effectively adjust educational strategies in the future.

# Contribution

**Xiaoting Tang**: Method, **Yifei Liu**: Result Display

**Longyu Zhang**: Interpretation, **Huanyu Chen**: Writing

\newpage
# Appendix

## Table

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Read and Clean Data
data =
  read_csv("./data.csv") |>
  janitor::clean_names() |>
  mutate(
    gender = factor(case_when(
      gender == "male" ~ 0,
      gender == "female" ~ 1,
      )),
    ethnic_group = factor(case_when(
      ethnic_group == "group A" ~ 0,
      ethnic_group == "group B" ~ 1,
      ethnic_group == "group C" ~ 2,
      ethnic_group == "group D" ~ 3,
      ethnic_group == "group E" ~ 4,
      )),
    parent_educ = factor(case_when(
      parent_educ == "some highschool" ~ 0,
      parent_educ == "some college" ~ 1,
      parent_educ == "associate's degree" ~ 2,
      parent_educ == "bachelor's degree" ~ 3,
      parent_educ == "master's degree" ~ 4,
      )),
    lunch_type = factor(case_when(
      lunch_type == "standard" ~ 0,
      lunch_type == "free/reduced" ~ 1,
      )),
    test_prep = factor(case_when(
      test_prep == "none" ~ 0,
      test_prep == "completed" ~ 1,
      )),
    parent_marital_status = factor(case_when(
      parent_marital_status == "married" ~ 0,
      parent_marital_status == "single" ~ 1,
      parent_marital_status == "widowed" ~ 2,
      parent_marital_status == "divorced" ~ 3,
      )),
    practice_sport = factor(case_when(
      practice_sport == "never" ~ 0,
      practice_sport == "sometimes" ~ 1,
      practice_sport == "regularly" ~ 2,
      )),
    is_first_child = factor(case_when(
      is_first_child == "no" ~ 0,
      is_first_child == "yes" ~ 1,
      )),
    transport_means = factor(case_when(
      transport_means == "school_bus" ~ 0,
      transport_means == "private" ~ 1,
      )),
    wkly_study_hours = factor(case_when(
      wkly_study_hours == "< 5" ~ 0,
      wkly_study_hours == "10-May" ~ 1,
      wkly_study_hours == "> 10" ~ 2,
      ))
    ) |>
  mutate(nr_siblings = factor(nr_siblings))

# Another data set for EDA
data_long <- data |>
  pivot_longer(cols = c(math_score, reading_score, writing_score),
               names_to = "test", values_to = "score")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Summary
sum_data_fct =
  data |>
  dplyr::select(1:11) |>
  skimr::skim() |>
  dplyr::select(skim_variable, n_missing, factor.n_unique, factor.top_counts)

colnames(sum_data_fct) = c("Variable", "Missing", "Unique", "Top Counts")

knitr::kable(x = sum_data_fct, caption = "Categorical Variables pre-analysis", digits = 1)

data =
  data |>
  drop_na()
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
sum_data_score =
  data |>
  dplyr::select(12:14) |>
  skimr::skim() |>
  dplyr::select(skim_variable, numeric.mean, numeric.sd, numeric.p0, numeric.p25, numeric.p50, numeric.p75, numeric.p100)

colnames(sum_data_score) = c("Variable", "Mean", "SD", "Min", "Q1", "Median", "Q3", "Max")

knitr::kable(x = sum_data_score, caption = "Continuous Variables pre-analysis", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# FULL MODEL
# Math
model_math_full = lm(math_score ~ . - reading_score - writing_score, data = data)

# Reading
model_reading_full = lm(reading_score ~ . - math_score - writing_score, data = data)

# Writing
model_writing_full = lm(writing_score ~ . - reading_score - math_score, data = data)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Stepwise Regressions
# math
math_sr = step(model_math_full, direction = 'both', trace = FALSE)

tb_math_sr = math_sr |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_math_sr) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_math_sr, caption = "Math Scores Models by Stepwise Regression", digits = 2)

# reading
rea_sr = step(model_reading_full, direction = 'both', trace = FALSE)

tb_rea_sr = rea_sr |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_rea_sr) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_rea_sr, caption = "Reading Scores Models by Stepwise Regression", digits = 2)

# writing
wri_sr = step(model_writing_full, direction = 'both', trace = FALSE)

tb_wri_sr = wri_sr |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_wri_sr) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_wri_sr, caption = "Writing Scores Models by Stepwise Regression", digits = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# check VIF
vif_math =
  performance::check_collinearity(model_math_full) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_math, caption = "VIF for Math Score", digits = 1)

vif_reading =
  performance::check_collinearity(model_reading_full) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_reading, caption = "VIF for Reading Score", digits = 1)

vif_writing =
  performance::check_collinearity(model_writing_full) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_writing, caption = "VIF for Writing Score", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
math_c = regsubsets(math_score ~ . - reading_score - writing_score, data = data)
res_math =
  math_c |>
  summary()

reading_c = regsubsets(reading_score ~ . - math_score - writing_score, data = data)
res_reading =
  math_c |>
  summary()

writing_c = regsubsets(writing_score ~ . - math_score - reading_score, data = data)
res_writing =
  math_c |>
  summary()

res_cb_math = 
  res_math$outmat[5,] |>
  as.matrix() |>
  as_tibble() |>
  mutate(term = rownames(as.matrix(res_math$outmat[5,]))) |>
  dplyr::select(term, everything()) |>
  filter(term != "(Intercept)") |>
  filter(V1 != 0)
colnames(res_cb_math) = c("Term", "Variable Selection")
knitr::kable(x = res_cb_math, caption = "Math Scores by Criterion-based Procedures", digits = 1)

res_cb_reading = 
  res_reading$outmat[5,] |>
  as.matrix() |>
  as_tibble() |>
  mutate(term = rownames(as.matrix(res_reading$outmat[5,]))) |>
  dplyr::select(term, everything()) |>
  filter(term != "(Intercept)") |>
  filter(V1 != 0)
colnames(res_cb_reading) = c("Term", "Variable Selection")
knitr::kable(x = res_cb_reading, caption = "Reading Scores by Criterion-based Procedures", digits = 1)

res_cb_writing = 
  res_writing$outmat[5,] |>
  as.matrix() |>
  as_tibble() |>
  mutate(term = rownames(as.matrix(res_writing$outmat[5,]))) |>
  dplyr::select(term, everything()) |>
  filter(term != "(Intercept)") |>
  filter(V1 != 0)
colnames(res_cb_writing) = c("Term", "Variable Selection")
knitr::kable(x = res_cb_writing, caption = "Writing Scores by Criterion-based Procedures", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
lambda_seq = 10 ^ seq(-2, 2, by = .1)

#math
cv_object_math = 
  cv.glmnet(as.matrix(data[1:11]), data$math_score,
                         lambda = lambda_seq,
                         nfolds = 5)

opt_lambda_math = cv_object_math$lambda.min

#math result
model_math_lasso = glmnet(as.matrix(data[1:11]), data$math_score, lambda = opt_lambda_math, alpha = 1)
res_math_lasso = 
  coef(model_math_lasso) |>
  as.matrix() |>
  as_tibble() |>
  mutate(term = rownames(coef(model_math_lasso))) |>
  dplyr::select(term, everything()) |>
  filter(term != "(Intercept)") |>
  filter(s0 != 0)
colnames(res_math_lasso) = c("Term", "Estimate")
knitr::kable(x = res_math_lasso, caption = "Math Scores Models by Lasso Model", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
#reading
cv_object_reading = 
  cv.glmnet(as.matrix(data[1:11]), data$reading_score,
                         lambda = lambda_seq,
                         nfolds = 5)

opt_lambda_reading = cv_object_reading$lambda.min

#reading result
model_reading_lasso = glmnet(as.matrix(data[1:11]), data$reading_score, lambda = opt_lambda_reading, alpha = 1)
res_reading_lasso = 
  coef(model_reading_lasso) |>
  as.matrix() |>
  as_tibble() |>
  mutate(term = rownames(coef(model_reading_lasso))) |>
  dplyr::select(term, everything()) |>
  filter(term != "(Intercept)") |>
  filter(s0 != 0)
colnames(res_reading_lasso) = c("Term", "Estimate")
knitr::kable(x = res_reading_lasso, caption = "Reading Scores Models by Lasso Model", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
#writing
cv_object_writing = 
  cv.glmnet(as.matrix(data[1:11]), data$writing_score,
                         lambda = lambda_seq,
                         nfolds = 5)

opt_lambda_writing = cv_object_writing$lambda.min

#writing result
model_writing_lasso = glmnet(as.matrix(data[1:11]), data$writing_score, lambda = opt_lambda_writing, alpha = 1)
res_writing_lasso = 
  coef(model_writing_lasso) |>
  as.matrix() |>
  as_tibble() |>
  mutate(term = rownames(coef(model_writing_lasso))) |>
  dplyr::select(term, everything()) |>
  filter(term != "(Intercept)") |>
  filter(s0 != 0)
colnames(res_writing_lasso) = c("Term", "Estimate")
knitr::kable(x = res_writing_lasso, caption = "Writing Scores Models by Lasso Model", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Math
math_reading = lm(math_score ~ . - writing_score, data = data) |>
  step(direction = "both", trace = FALSE)

math_reading_sum =
  math_reading |> 
  summary()

tb_math_reading = 
  math_reading_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_math_reading) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_math_reading, caption = "Math Scores Models Using Reading Score as Additional Predictor", digits = 1)

math_writing = lm(math_score ~ . - reading_score, data = data) |>
  step(direction = "both", trace = FALSE)

math_writing_sum =
  math_writing |> 
  summary()

tb_math_writing = 
  math_writing_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_math_writing) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_math_writing, caption = "Math Scores Models Using Writing Score as Additional Predictor", digits = 1)

# Reading
reading_math = lm(reading_score ~ . - writing_score, data = data) |>
  step(direction = "both", trace = FALSE)

reading_math_sum =
  reading_math |> 
  summary()

tb_reading_math = 
  reading_math_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_reading_math) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_reading_math, caption = "Reading Scores Models Using Math Score as Additional Predictor", digits = 1)

reading_writing = lm(reading_score ~ . - math_score, data = data) |>
  step(direction = "both", trace = FALSE)

reading_writing_sum =
  reading_writing |> 
  summary()

tb_reading_writing = 
  reading_writing_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_reading_writing) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_reading_writing, caption = "Reading Scores Models Using Writing Score as Additional Predictor", digits = 1)

# Writing
writing_math = lm(writing_score ~ . - reading_score, data = data) |>
  step(direction = "both", trace = FALSE)

writing_math_sum =
  writing_math |> 
  summary()

tb_writing_math = 
  writing_math_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_writing_math) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_writing_math, caption = "Writing Scores Models Using Math Score as Additional Predictor", digits = 1)

writing_reading = lm(writing_score ~ . - math_score, data = data) |>
  step(direction = "both", trace = FALSE)

writing_reading_sum =
  writing_reading |> 
  summary()

tb_writing_reading = 
  writing_reading_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_writing_reading) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_writing_reading, caption = "Writing Scores Models Using Reading Score as Additional Predictor", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# check VIF
vif_math_reading =
  performance::check_collinearity(math_reading) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_math_reading, caption = "VIF for Math Score (include reading score)", digits = 1)

vif_math_writing =
  performance::check_collinearity(math_writing) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_math_writing, caption = "VIF for Math Score (include writing score)", digits = 1)

vif_reading_math =
  performance::check_collinearity(reading_math) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_reading_math, caption = "VIF for Reading Score (include math score)", digits = 1)

vif_reading_writing =
  performance::check_collinearity(reading_writing) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_reading_writing, caption = "VIF for Reading Score (include writing score)", digits = 1)

vif_writing_math =
  performance::check_collinearity(writing_math) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_writing_math, caption = "VIF for Writing Score (include math score)", digits = 1)

vif_writing_reading =
  performance::check_collinearity(writing_reading) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_writing_reading, caption = "VIF for Writing Score (include reading score)", digits = 1)
```

## Figure

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Histograms
data_long |>
  ggplot(aes(x = score, fill = test)) +
  geom_histogram(binwidth = 8, color = "#013571") +
  labs(
    title = "Figure 1: Scores Histograms by Subjects",
    x = "Score",
    y = "Count"
    ) +
  scale_fill_manual(values = c("#2E4E7D", "#405165", "#67A9CB")) +
  facet_grid(~ test) +
  theme_bw() +
  theme(legend.position = "bottom") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Boxplots
data_long |>
  ggplot(aes(x = test, y = score, fill = test)) +
  geom_boxplot() +
  labs(
    title = "Figure 2: Scores Boxplot by Subjects",
    x = "Test",
    y = "Score"
    ) +
  facet_wrap(~ test, scales = "free") +
  scale_fill_manual(values = c("#2E4E7D", "#405165", "#67A9CB")) +
  theme_bw() +
  theme(legend.position = "bottom") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
par(mfrow = c(2, 2))
plot(math_sr, which = 1)
plot(math_sr, which = 2)
plot(math_sr, which = 3)
plot(math_sr, which = 4)
main_title <- "Figure 3: Diagnostic Plots for Math Test Score (Stepwise)"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)


par(mfrow = c(2, 2))
plot(rea_sr, which = 1)
plot(rea_sr, which = 2)
plot(rea_sr, which = 3)
plot(rea_sr, which = 4)
main_title <- "Figure 4: Diagnostic Plots for Reading Test Score (Stepwise)"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)


par(mfrow = c(2, 2))
plot(wri_sr, which = 1)
plot(wri_sr, which = 2)
plot(wri_sr, which = 3)
plot(wri_sr, which = 4)
main_title <- "Figure 5: Diagnostic Plots for Writing Test Score (Stepwise)"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Transformation
par(mfrow = c(1, 3), mar = c(8, 4, 4, 1))
boxcox(model_math_full)
title(sub = "Math")
boxcox(model_reading_full)
title(sub = "Reading")
boxcox(model_writing_full)
title(sub = "Writing")
main_title <- "Figure 6: Boxcox Method"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Outlier and influence points
par(mfrow = c(1, 3), mar = c(8, 4, 4, 1))
plot(model_math_full, which = 4)
title(sub = "Math")
plot(model_reading_full, which = 4)
title(sub = "Reading")
plot(model_writing_full, which = 4)
title(sub = "Writing")
main_title <- "Figure 7: Cook's Distance"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# BIC for three models
math_c = regsubsets(math_score ~ . - reading_score - writing_score, data = data)
res_math =
  math_c |>
  summary()

reading_c = regsubsets(reading_score ~ . - math_score - writing_score, data = data)
res_reading =
  reading_c |>
  summary()

writing_c = regsubsets(writing_score ~ . - math_score - reading_score, data = data)
res_writing =
  writing_c |>
  summary()

par(mfrow = c(1, 3), mar = c(8, 4, 4, 1))
plot(1:8, res_math$bic, xlab = "# of parameters", ylab = "BIC")
title(sub = "Math")
plot(1:8, res_reading$bic, xlab = "# of parameters", ylab = "BIC")
title(sub = "Reading")
plot(1:8, res_writing$bic, xlab = "# of parameters", ylab = "BIC")
title(sub = "Writing")
main_title <- "Figure 8: BIC Over Number of Parameters for Models of Three Subjects"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# lasso lambda for math
lambda_seq = 10 ^ seq(-2, 2, by = .1)

cv_object_math = 
  cv.glmnet(as.matrix(data[1:11]), data$math_score,
                         lambda = lambda_seq,
                         nfolds = 5)

opt_lambda_math = cv_object_math$lambda.min

tb_la_math = tibble(
  lambda = cv_object_math$lambda,
  mean_cv_error = cv_object_math$cvm) |>
  filter(lambda < 1)

tb_la_math |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point() +
  theme_bw() +
  labs(title = "Figure 9: Mean CV Error vs. Lambda for Math") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# lasso lambda for reading
cv_object_reading = 
  cv.glmnet(as.matrix(data[1:11]), data$reading_score,
                         lambda = lambda_seq,
                         nfolds = 5)

opt_lambda_reading = cv_object_reading$lambda.min

tb_la_reading = tibble(
  lambda = cv_object_reading$lambda,
  mean_cv_error = cv_object_reading$cvm) |>
  filter(lambda < 1)

tb_la_reading |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point() +
  theme_bw() +
  labs(title = "Figure 10: Mean CV Error vs. Lambda for Reading") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# lasso lambda for writing
cv_object_writing = 
  cv.glmnet(as.matrix(data[1:11]), data$writing_score,
                         lambda = lambda_seq,
                         nfolds = 5)

opt_lambda_writing = cv_object_writing$lambda.min

tb_la_writing = tibble(
  lambda = cv_object_writing$lambda,
  mean_cv_error = cv_object_writing$cvm) |>
  filter(lambda < 1)

tb_la_writing |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point() +
  theme_bw() +
  labs(title = "Figure 11: Mean CV Error vs. Lambda for Writing") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
#math
glmnet(as.matrix(data[1:11]), data$math_score, lambda = lambda_seq) |>
  broom::tidy() |>
  dplyr::select(term, lambda, estimate) |> 
  complete(term, lambda, fill = list(estimate = 0) ) |> 
  filter(term != "(Intercept)") |> 
  ggplot(aes(x = log(lambda, 10), y = estimate, group = term, color = term)) + 
  geom_path(size = 0.8) + 
  geom_vline(xintercept = log(opt_lambda_math, 10), color = "red", linetype = "dashed", size = 1) +
  labs(title = "Figure 12: Lasso Variables Contraction for Math") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5), legend.position = "bottom")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
#reading
glmnet(as.matrix(data[1:11]), data$reading_score, lambda = lambda_seq) |>
  broom::tidy() |>
  dplyr::select(term, lambda, estimate) |> 
  complete(term, lambda, fill = list(estimate = 0) ) |> 
  filter(term != "(Intercept)") |> 
  ggplot(aes(x = log(lambda, 10), y = estimate, group = term, color = term)) + 
  geom_path(size = 0.8) + 
  geom_vline(xintercept = log(opt_lambda_reading, 10), color = "red", linetype = "dashed", size = 1) +
  labs(title = "Figure 13: Lasso Variables Contraction for Reading") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5), legend.position = "bottom")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
#writing
glmnet(as.matrix(data[1:11]), data$writing_score, lambda = lambda_seq) |>
  broom::tidy() |>
  dplyr::select(term, lambda, estimate) |> 
  complete(term, lambda, fill = list(estimate = 0) ) |> 
  filter(term != "(Intercept)") |> 
  ggplot(aes(x = log(lambda, 10), y = estimate, group = term, color = term)) + 
  geom_path(size = 0.8) + 
  geom_vline(xintercept = log(opt_lambda_writing, 10), color = "red", linetype = "dashed", size = 1) +
  labs(title = "Figure 14: Lasso Variables Contraction for writing") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5), legend.position = "bottom")
```

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width = 6, fig.height = 7}
# Correlation Plot among Score Variables
corrplot(cor(data[12:14]), type = "upper")
main_title <- "Figure 15: Correlation Plot among Score Variables"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```
