---
title: "**P8130 Final Report (Project 1)**"
author: 
- "Huanyu Chen (hc3451)   Xiaoting Tang (xt2288)"
- "Yifei Liu (yl5508)     Longyu Zhang (lz2951)"
output:
  pdf_document:
    latex_engine: pdflatex
fontsize: 11pt
linestretch: 2
---

```{r, include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
library(MASS)
library(glmnet)
library(leaps)

set.seed(1)
```

# Abstract
This study used regression modeling techniques to predict academic performance in math, reading, and writing based on multiple variables, including personal characteristics and environmental factors. Using stepwise regression and LASSO analyses, we found significant relationships between test scores and several covariants, including gender, race, parent education, lunch type, test preparation, and weekly study time. We further found that including another test score as a predictor (e.g., consider reading scores when predicting math scores) significantly enhanced model performance without destroying the effect of the existing predictor. This comprehensive analysis reveals the complex relationships between predictors and student performance, providing suggestions to educators and thus achieving overall student progress.

# Introduction

The objective of this study is to use regression models to predict
academic performance in math, reading, and writing based on various
variables, including personal characteristics such as gender, ethnicity,
and parental education, as well as environmental factors like lunch
type, test preparation, and weekly study hours. Furthermore, the study
aims to identify potential correlations and regression model between
scores in different subjects. The combination of these analyses is
intended to provide educators and policymakers with practical insights
for tailoring interventions, improving educational programs, and
building strong support structures that promote students' overall
academic progress.

# Methods

This dataset provides information on public school students, including
three test scores and various personal and socioeconomic factors. To
facilitate analysis, categorical data have been converted to numerical
representations based on their ordinal order or type. We have excluded
the missing cells because they are factorial data types.

After processing the data, we created **Table 1**, which presents a
summary of the factorial data, including the number of missing data, the
number of categories under each variable, and the top counts. For the
numeric data (three test scores), we constructed a comprehensive
descriptive table (**Table 2**) to provide a snapshot of central
tendencies and variability. The distribution of the three response
variables (test scores) is presented in **Figure 1** (histogram) and
**Figure 2** (boxplot), indicating a normal distribution.

Then we fitted the "full model" using the score of three subjects
respectively as the response variables, which consists of all 11
categorical variables as predictors. The model diagnostics are conducted
by generating four plot for each model: Residuals vs Fitted, Q-Q
Residuals, Scale-Location and Residuals vs Leverage (**Figure 3,4,5**).
Next, we use BIC-based procedures to select the appropriate subsets of
predictors for three subjects (**Figure 6,7,8,9**).

Based on the full models, we did some tests and calculations:

First, we conducted boxcox method (**Figure 10**) to determine if there's any transformation needed. Second, calculated Cook's distance (**Figure 11**) to check the existence of outliers and influence points. Finally, in order to test the multicollinearity among predictors, we calculated VIF as the criterion of multicollinearity (**Table 3,4,5**).

After all the steps above, we conducted model selection using both
stepwise selection method and LASSO method. For stepwise method, the
remaining predictors, coefficients and p-values are reported in **Table
6,7,8**.

In the selection procedure using LASSO method, for each subject we used
cross-validation to decide the optimal value of method parameter
$\lambda$, and then fitted LASSO model with this optimal value (**Figure
12,13,14**).

Finally, we tried to figure out if it is possible to leverage one score
as the auxiliary information to learn the model for another score (still
its model against variables 1-11) better. we plotted the correlation
among three score variables (**Figure 15**). Then we refitted the linear
models for the scores of three subjects using eleven categorical
variables and one other score variable of a different subject as
predictors (**Table 9,10,11,12,13,14**). The VIFs are calculated for all
six models generated in this step to reveal the potential
multicollinearity (**Table 15,16,17,18,19,20**).

# Results

**Table 1** gives the summary of the factorial data. **Table 2**
provides the mean, deviation and quantile information about the
continuous data (score variables of three subjects). The distribution of
three response score variables are demonstrated by **Figure 1**
(histogram) and **Figure 2** (boxplot).

**Table 6**, **Table 7**, and **Table 8** display the regression models
for math, reading, and writing scores using both forward and backward
stepwise regression. Moreover, **Figures 3**, **Figures 4**, and
**Figures 5** display the diagnostic plots generated by the model.

**Figure 6** displays the BIC over number of parameters for models of
three subjects. **Figure 7,8,9** shows the BIC consistent with the
remaining predictors in models of three subjects.

**Figure 10** demonstrates the results of boxcox method: the
log-likelihood over boxcox method parameter $\lambda$, and **Figure 11**
demonstrates the Cook's distance as the result of testing of outliers.

**Table 3,4,5** display the result of multicollinearity test: VIFs for
three full models.

**Figure 12,13,14** are plots of mean cross-validation error over LASSO
parameter $\lambda$, providing information about optimal values of
$\lambda$ for LASSO models. These optimal values are used for following
fitting of LASSO models.

**Figure 15** shows the correlation existing among score variables,
suggesting the feasibility of using one of the score variables as the
auxiliary information to learn the model for another score. **Table
9,10,11,12,13,14** are the results of regression using one subject score
as additional predictor for the prediction of another subject score.
**Table 15,16,17,18,19,20** shows the VIFs of these six models,
indicating the multicollinearity among predictors.

# Conclusions

Both the histogram and boxplot distributions showed a normal distribution. Moreover, the full model diagnosis indicated that there was no need for transformations of the test scores and that there was no multicollinearity among predictors. Criterion-based procedures suggest that employing regression models for three test scores with 4â€“5 predictors will yield optimal results with a minimum Bayesian information criterion. These approaches guide the construction of effective models for the three test scores.

The stepwise regression and LASSO techniques revealed significant predictors for math, reading, and writing scores. To be specific, gender, ethnic group, lunch type, test preparation, parent marital status, and weekly study hours were found to be significant variables for math scores, with an adjusted R-squared of 0.2742. In addition, LASSO expanded the model by including parental education, time spent in sports, and the number of siblings.

Similarly, the stepwise regression models for reading and writing scores also revealed statistically significant relationships between test scores and predictors, including gender, ethnicity, parental education, lunch type, test preparation, parental marital status, and weekly study hours. These predictors explain the model with an adjusted R-squared of 0.2513 for reading and 0.3298 for writing. Furthermore, the LASSO analysis expands the models by including two variables: whether the student is the first child and the number of siblings.

Furthermore, the inclusion of an additional test score as a predictor resulted in a significant increase in the adjusted R square to greater than 0.8 without introducing collinearity problems or altering the effects of the existing predictors. This emphasizes the interdependence of test scores and their potential as predictive variables for each other, thereby enhancing the models' predictive capacity.

The combination of various analytical approaches not only identified important factors affecting test scores but also established the best model structures, leading to a detailed comprehension of the complex relationship between predictors and student test results. This thorough analysis provides a basis for making informed decisions and implementing targeted interventions to improve academic performance and promote fair educational outcomes.

# Contribution

**Xiaoting Tang**: Method, **Yifei Liu**: Result Display

**Longyu Zhang**: Interpretation, **Huanyu Chen**: Writing

# Appendix

## Table

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Read and Clean Data
data =
  read_csv("./data.csv") |>
  janitor::clean_names() |>
  mutate(
    gender = factor(case_when(
      gender == "male" ~ 0,
      gender == "female" ~ 1,
      )),
    ethnic_group = factor(case_when(
      ethnic_group == "group A" ~ 0,
      ethnic_group == "group B" ~ 1,
      ethnic_group == "group C" ~ 2,
      ethnic_group == "group D" ~ 3,
      ethnic_group == "group E" ~ 4,
      )),
    parent_educ = factor(case_when(
      parent_educ == "some highschool" ~ 0,
      parent_educ == "some college" ~ 1,
      parent_educ == "associate's degree" ~ 2,
      parent_educ == "bachelor's degree" ~ 3,
      parent_educ == "master's degree" ~ 4,
      )),
    lunch_type = factor(case_when(
      lunch_type == "standard" ~ 0,
      lunch_type == "free/reduced" ~ 1,
      )),
    test_prep = factor(case_when(
      test_prep == "none" ~ 0,
      test_prep == "completed" ~ 1,
      )),
    parent_marital_status = factor(case_when(
      parent_marital_status == "married" ~ 0,
      parent_marital_status == "single" ~ 1,
      parent_marital_status == "widowed" ~ 2,
      parent_marital_status == "divorced" ~ 3,
      )),
    practice_sport = factor(case_when(
      practice_sport == "never" ~ 0,
      practice_sport == "sometimes" ~ 1,
      practice_sport == "regularly" ~ 2,
      )),
    is_first_child = factor(case_when(
      is_first_child == "no" ~ 0,
      is_first_child == "yes" ~ 1,
      )),
    transport_means = factor(case_when(
      transport_means == "school_bus" ~ 0,
      transport_means == "private" ~ 1,
      )),
    wkly_study_hours = factor(case_when(
      wkly_study_hours == "< 5" ~ 0,
      wkly_study_hours == "10-May" ~ 1,
      wkly_study_hours == "> 10" ~ 2,
      ))
    ) |>
  mutate(nr_siblings = factor(nr_siblings))

# Another data set for EDA
data_long <- data |>
  pivot_longer(cols = c(math_score, reading_score, writing_score),
               names_to = "test", values_to = "score")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Summary
sum_data_fct =
  data |>
  dplyr::select(1:11) |>
  skimr::skim() |>
  dplyr::select(skim_variable, n_missing, factor.n_unique, factor.top_counts)

colnames(sum_data_fct) = c("Variable", "Missing", "Unique", "Top Counts")

knitr::kable(x = sum_data_fct, caption = "Categorical Variables pre-analysis", digits = 1)

data =
  data |>
  drop_na()
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
sum_data_score =
  data |>
  dplyr::select(12:14) |>
  skimr::skim() |>
  dplyr::select(skim_variable, numeric.mean, numeric.sd, numeric.p0, numeric.p25, numeric.p50, numeric.p75, numeric.p100)

colnames(sum_data_score) = c("Variable", "Mean", "SD", "Min", "Q1", "Median", "Q3", "Max")

knitr::kable(x = sum_data_score, caption = "Continuous Variables pre-analysis", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# FULL MODEL
# Math
model_math_full = lm(math_score ~ . - reading_score - writing_score, data = data)

# Reading
model_reading_full = lm(reading_score ~ . - math_score - writing_score, data = data)

# Writing
model_writing_full = lm(writing_score ~ . - reading_score - math_score, data = data)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Stepwise Regressions
# math
math_sr = step(model_math_full, direction = 'both', trace = FALSE)

tb_math_sr = math_sr |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_math_sr) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_math_sr, caption = "Math Scores Models by Stepwise Regression", digits = 2)

# reading
rea_sr = step(model_reading_full, direction = 'both', trace = FALSE)

tb_rea_sr = rea_sr |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_rea_sr) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_rea_sr, caption = "Reading Scores Models by Stepwise Regression", digits = 2)

# writing
wri_sr = step(model_writing_full, direction = 'both', trace = FALSE)

tb_wri_sr = wri_sr |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_wri_sr) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_wri_sr, caption = "Writing Scores Models by Stepwise Regression", digits = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# check VIF
vif_math =
  performance::check_collinearity(model_math_full) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_math, caption = "VIF for Math Score", digits = 1)

vif_reading =
  performance::check_collinearity(model_reading_full) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_reading, caption = "VIF for Reading Score", digits = 1)

vif_writing =
  performance::check_collinearity(model_writing_full) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_writing, caption = "VIF for Reading Score", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Math
math_reading = lm(math_score ~ . - writing_score, data = data) |>
  step(direction = "both", trace = FALSE)

math_reading_sum =
  math_reading |> 
  summary()

tb_math_reading = 
  math_reading_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_math_reading) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_math_reading, caption = "Math Scores Models Using Reading Score as Additional Predictor", digits = 1)

math_writing = lm(math_score ~ . - reading_score, data = data) |>
  step(direction = "both", trace = FALSE)

math_writing_sum =
  math_writing |> 
  summary()

tb_math_writing = 
  math_writing_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_math_writing) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_math_writing, caption = "Math Scores Models Using Writing Score as Additional Predictor", digits = 1)

# Reading
reading_math = lm(reading_score ~ . - writing_score, data = data) |>
  step(direction = "both", trace = FALSE)

reading_math_sum =
  reading_math |> 
  summary()

tb_reading_math = 
  reading_math_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_reading_math) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_reading_math, caption = "Reading Scores Models Using Math Score as Additional Predictor", digits = 1)

reading_writing = lm(reading_score ~ . - math_score, data = data) |>
  step(direction = "both", trace = FALSE)

reading_writing_sum =
  reading_writing |> 
  summary()

tb_reading_writing = 
  reading_writing_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_reading_writing) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_reading_writing, caption = "Reading Scores Models Using Writing Score as Additional Predictor", digits = 1)

# Writing
writing_math = lm(writing_score ~ . - reading_score, data = data) |>
  step(direction = "both", trace = FALSE)

writing_math_sum =
  writing_math |> 
  summary()

tb_writing_math = 
  writing_math_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_writing_math) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_writing_math, caption = "Writing Scores Models Using Math Score as Additional Predictor", digits = 1)

writing_reading = lm(writing_score ~ . - math_score, data = data) |>
  step(direction = "both", trace = FALSE)

writing_reading_sum =
  writing_reading |> 
  summary()

tb_writing_reading = 
  writing_reading_sum |>
  broom::tidy() |>
  filter(term != "(Intercept)") |> 
  dplyr::select(term, estimate, p.value)
colnames(tb_writing_reading) = c("Term", "Estimate", "P Value")
knitr::kable(x = tb_writing_reading, caption = "Writing Scores Models Using Reading Score as Additional Predictor", digits = 1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# check VIF
vif_math_reading =
  performance::check_collinearity(math_reading) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_math_reading, caption = "VIF for Math Score (include reading score)", digits = 1)

vif_math_writing =
  performance::check_collinearity(math_writing) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_math_writing, caption = "VIF for Math Score (include writing score)", digits = 1)

vif_reading_math =
  performance::check_collinearity(reading_math) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_reading_math, caption = "VIF for Reading Score (include math score)", digits = 1)

vif_reading_writing =
  performance::check_collinearity(reading_writing) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_reading_writing, caption = "VIF for Reading Score (include writing score)", digits = 1)

vif_writing_math =
  performance::check_collinearity(writing_math) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_writing_math, caption = "VIF for Writing Score (include math score)", digits = 1)

vif_writing_reading =
  performance::check_collinearity(writing_reading) |>
  as_tibble() |>
  mutate(VIF_CI = str_c("[", round(VIF_CI_low, 1), ", ", round(VIF_CI_high, 1), "]")) |>
  dplyr::select(Term, VIF, VIF_CI, Tolerance)
knitr::kable(x = vif_writing_reading, caption = "VIF for Writing Score (include reading score)", digits = 1)
```

## Figure

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Histograms
data_long |>
  ggplot(aes(x = score, fill = test)) +
  geom_histogram(binwidth = 8, color = "#013571") +
  labs(
    title = "Figure 1: Scores Histograms by Subjects",
    x = "Score",
    y = "Count"
    ) +
  scale_fill_manual(values = c("#2E4E7D", "#405165", "#67A9CB")) +
  facet_grid(~ test) +
  theme_bw() +
  theme(legend.position = "bottom") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Boxplots
data_long |>
  ggplot(aes(x = test, y = score, fill = test)) +
  geom_boxplot() +
  labs(
    title = "Figure 2: Scores Boxplot by Subjects",
    x = "Test",
    y = "Score"
    ) +
  facet_wrap(~ test, scales = "free") +
  scale_fill_manual(values = c("#2E4E7D", "#405165", "#67A9CB")) +
  theme_bw() +
  theme(legend.position = "bottom") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
par(mfrow = c(2, 2))
plot(math_sr, which = 1)
plot(math_sr, which = 2)
plot(math_sr, which = 3)
plot(math_sr, which = 4)
main_title <- "Figure 3: Diagnostic Plots for Math Test Score (Stepwise)"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)


par(mfrow = c(2, 2))
plot(rea_sr, which = 1)
plot(rea_sr, which = 2)
plot(rea_sr, which = 3)
plot(rea_sr, which = 4)
main_title <- "Figure 4: Diagnostic Plots for Reading Test Score (Stepwise)"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)


par(mfrow = c(2, 2))
plot(wri_sr, which = 1)
plot(wri_sr, which = 2)
plot(wri_sr, which = 3)
plot(wri_sr, which = 4)
main_title <- "Figure 5: Diagnostic Plots for Writing Test Score (Stepwise)"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# BIC for three models
math_c = regsubsets(math_score ~ . - reading_score - writing_score, data = data)
res_math =
  math_c |>
  summary()

reading_c = regsubsets(reading_score ~ . - math_score - writing_score, data = data)
res_reading =
  reading_c |>
  summary()

writing_c = regsubsets(writing_score ~ . - math_score - reading_score, data = data)
res_writing =
  writing_c |>
  summary()

par(mfrow = c(1, 3), mar = c(8, 4, 4, 1))
plot(1:8, res_math$bic, xlab = "# of parameters", ylab = "BIC")
title(sub = "Math")
plot(1:8, res_reading$bic, xlab = "# of parameters", ylab = "BIC")
title(sub = "Reading")
plot(1:8, res_writing$bic, xlab = "# of parameters", ylab = "BIC")
title(sub = "Writing")
main_title <- "Figure 6: BIC Over Number of Parameters for Models of Three Subjects"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# BIC for Math
plot(math_c, scale = "bic")
main_title <- "Figure 7: BIC for Math Score"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# BIC for Reading
plot(reading_c, scale = "bic")
main_title <- "Figure 8: BIC for Reading Score"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# BIC for Writing
plot(writing_c, scale = "bic")
main_title <- "Figure 9: BIC for Writing Score"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Transformation
par(mfrow = c(1, 3), mar = c(8, 4, 4, 1))
boxcox(model_math_full)
title(sub = "Math")
boxcox(model_reading_full)
title(sub = "Reading")
boxcox(model_writing_full)
title(sub = "Writing")
main_title <- "Figure 10: Boxcox Method"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Outlier and influence points
par(mfrow = c(1, 3), mar = c(8, 4, 4, 1))
plot(model_math_full, which = 4)
title(sub = "Math")
plot(model_reading_full, which = 4)
title(sub = "Reading")
plot(model_writing_full, which = 4)
title(sub = "Writing")
main_title <- "Figure 11: Cook's Distance"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# lasso lambda for math
lambda_seq = 10 ^ seq(-2, 2, by = .1)

cv_object_math = 
  cv.glmnet(as.matrix(data[1:11]), data$math_score,
                         lambda = lambda_seq,
                         nfolds = 5)

opt_lambda_math = cv_object_math$lambda.min

tb_la_math = tibble(
  lambda = cv_object_math$lambda,
  mean_cv_error = cv_object_math$cvm) |>
  filter(lambda < 1)

tb_la_math |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point() +
  theme_bw() +
  labs(title = "Figure 12: Mean CV Error vs. Lambda for Math") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))

```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# lasso lambda for reading
cv_object_reading = 
  cv.glmnet(as.matrix(data[1:11]), data$reading_score,
                         lambda = lambda_seq,
                         nfolds = 5)

opt_lambda_reading = cv_object_reading$lambda.min

tb_la_reading = tibble(
  lambda = cv_object_reading$lambda,
  mean_cv_error = cv_object_reading$cvm) |>
  filter(lambda < 1)

tb_la_reading |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point() +
  theme_bw() +
  labs(title = "Figure 13: Mean CV Error vs. Lambda for Reading") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))

```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# lasso lambda for writing
cv_object_writing = 
  cv.glmnet(as.matrix(data[1:11]), data$writing_score,
                         lambda = lambda_seq,
                         nfolds = 5)

opt_lambda_writing = cv_object_writing$lambda.min

tb_la_writing = tibble(
  lambda = cv_object_writing$lambda,
  mean_cv_error = cv_object_writing$cvm) |>
  filter(lambda < 1)

tb_la_writing |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point() +
  theme_bw() +
  labs(title = "Figure 14: Mean CV Error vs. Lambda for Writing") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Correlation Plot among Score Variables
corrplot::corrplot(cor(data[12:14]), type = "upper")
main_title <- "Figure 15: Correlation Plot among Score Variables"
mtext(text = main_title, side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
```
